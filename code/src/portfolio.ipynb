{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Warnings\n",
    "import warnings;\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Path\n",
    "ROOT_PATH = os.path.abspath(os.path.join('../' + os.path.dirname('__file__')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df, binary = False):\n",
    "    if binary == True:\n",
    "        list_columns = list(df.columns)\n",
    "        for col in list_columns:\n",
    "            col_temp = []\n",
    "            for i in range(len(df)):\n",
    "                if df[col].iloc[i] <= 0:\n",
    "                    col_temp.append(0)\n",
    "                else:\n",
    "                    col_temp.append(1)\n",
    "            df[col] = col_temp\n",
    "    return df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para detectar outliers\n",
    "def detect_outliers(column):\n",
    "    # Calcular el límite inferior y superior usando la regla empírica\n",
    "    lower_limit = column.mean() - 2*column.std()\n",
    "    upper_limit = column.mean() + 2*column.std()\n",
    "    \n",
    "    # Devolver una máscara booleana que indica si cada valor es un outlier o no\n",
    "    return (column < lower_limit) | (column > upper_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_outlier(outlier_df, df_OG):\n",
    "    df_nooutlier = outlier_df.copy()\n",
    "    list_columns = list(outlier_df.columns)\n",
    "    for col in list_columns:\n",
    "        col_temp = []\n",
    "        col_temp_2 = []\n",
    "        for i in range(len(outlier_df)):\n",
    "            if outlier_df[col].iloc[i] == False:\n",
    "                col_temp.append(np.nan)\n",
    "                col_temp_2.append(df_OG[col].iloc[i])\n",
    "            else:\n",
    "                col_temp.append(df_OG[col].iloc[i])\n",
    "                col_temp_2.append(np.nan)\n",
    "        outlier_df[col] = col_temp\n",
    "        df_nooutlier[col] = col_temp_2\n",
    "    for f in list(df_nooutlier.columns):\n",
    "        df_nooutlier[f] = df_nooutlier[f].interpolate(method='linear', axis=0).ffill().bfill()\n",
    "    return outlier_df, df_nooutlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grapfh(df_outlier, df_no_outlier):\n",
    "    with plt.style.context('fivethirtyeight'):\n",
    "        for num, nombre_vble in enumerate(list(df_no_outlier.columns)):\n",
    "            fig, ax = plt.subplots(figsize=(25, 5))\n",
    "            \n",
    "            plt.plot(df_outlier[nombre_vble], color='r', label = 'normal')\n",
    "            plt.plot(df_no_outlier[nombre_vble], color='#0c2f22', label = 'no_atipic')\n",
    "            \n",
    "            plt.xlabel('Fecha')\n",
    "            plt.ylabel('valor')\n",
    "            plt.title(nombre_vble)\n",
    "            plt.grid(True)\n",
    "            plt.legend(loc='upper right')\n",
    "            path_graph = os.path.join(\n",
    "                    ROOT_PATH,\n",
    "                    'data',\n",
    "                    'portfolio',\n",
    "                    'output',\n",
    "                    nombre_vble +\n",
    "                    '_plot.png')\n",
    "            plt.savefig(path_graph)\n",
    "            # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar data\n",
    "data38_OG = pd.read_excel(ROOT_PATH +\"/data/portfolio/input/raw/data38.xlsx\").set_index('date')\n",
    "\n",
    "# Volver la data binaria\n",
    "binary = False\n",
    "data38 = transform_data(data38_OG.copy(), binary)\n",
    "\n",
    "# Detectar atípicos\n",
    "outliers = data38.apply(detect_outliers)\n",
    "\n",
    "# Calcular la cantidad de outliers en cada columna\n",
    "prop_outliers_vble = outliers.sum(axis = 0)\n",
    "prop_outliers_date = outliers.sum(axis = 1)\n",
    "\n",
    "# Saco dos df, con y sin outliers\n",
    "outlier_df, df_nooutlier =  df_outlier(outliers.copy(), data38_OG.copy())\n",
    "\n",
    "# Gráficar salidas con outliers\n",
    "plot_grapfh(outlier_df, df_nooutlier)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covarianza"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calcular la matriz de covarianzas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Número condición de la matriz de covarianzas: 1368.494259473167\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "cov_matrix = np.cov(data38_OG.T)\n",
    "cond_num = np.linalg.eigvals(cov_matrix)\n",
    "cond_num = np.sort(cond_num)[::-1]\n",
    "cond_number = cond_num[0] / cond_num[-1]\n",
    "print(\"-\"*17)\n",
    "print(\"Número condición de la matriz de covarianzas:\", cond_number)\n",
    "print(\"-\"*17)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Para reducir el número condición de la matriz de covarianzas, podemos utilizar técnicas de regularización. Una forma común de regularización es agregar un término de regularización a la matriz de covarianzas, lo que reduce la magnitud de los valores propios más grandes y mejora el número condición.\n",
    "\n",
    "##### En este ejemplo, agregamos un término de regularización igual a 0.1 veces la matriz identidad multiplicada por el número de columnas de la matriz de covarianzas. Este término de regularización aumenta la diagonal de la matriz de covarianzas en un factor constante, lo que reduce el número condición. Al ajustar el valor de la constante de regularización, podemos encontrar un equilibrio entre mejorar el número condición y mantener la calidad de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Número condición de la matriz de covarianzas regularizada: 1325.6003672261263\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Regularizar la matriz de covarianzas\n",
    "cov_mat_reg = cov_matrix + 0.1*np.identity(cov_matrix.shape[0])\n",
    "cond_num_reg = np.linalg.cond(cov_mat_reg)\n",
    "\n",
    "print(\"-\"*17)\n",
    "print(\"Número condición de la matriz de covarianzas regularizada:\", cond_num_reg)\n",
    "print(\"-\"*17)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Otra forma de reducir el número condición de la matriz de covarianzas es aplicar una técnica de reducción de dimensionalidad, como Análisis de Componentes Principales (PCA). PCA reduce el número de dimensiones de la base de datos al proyectar los datos en un espacio de menor dimensión que conserva la mayor parte de la varianza en los datos. Esto puede ayudar a reducir el número condición de la matriz de covarianzas y mejorar la calidad de los datos.\n",
    "\n",
    "##### En este ejemplo, utilizamos la implementación de PCA en la biblioteca scikit-learn para reducir las dimensiones de la base de datos a 2 componentes principales. Luego, calculamos la matriz de covarianzas de los datos transformados y el número condición correspondiente. Notamos que en comparación con la matriz de covarianzas original, la matriz de covarianzas de los datos transformados tiene un número condición mucho menor, lo que indica una mayor estabilidad numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número condición de la matriz de covarianzas de los datos transformados: 337.3378797736535\n"
     ]
    }
   ],
   "source": [
    "# Reducción de dimensionalidad utilizando PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Instanciar PCA con número de componentes igual a 10\n",
    "pca = PCA(n_components=25)\n",
    "\n",
    "# Ajustar y transformar los datos a las nuevas dimensiones\n",
    "data_pca = pca.fit_transform(data38_OG.copy())\n",
    "\n",
    "# Calcular matriz de covarianzas y número condición de los datos transformados\n",
    "cov_mat_pca = np.cov(data_pca.T)\n",
    "cond_num_pca = np.linalg.cond(cov_mat_pca)\n",
    "\n",
    "print(\"Número condición de la matriz de covarianzas de los datos transformados:\", cond_num_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
